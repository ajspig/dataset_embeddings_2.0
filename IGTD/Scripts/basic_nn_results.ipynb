{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file was run on a jupyterhub. It needs optim_maxes.csv and IGTD.csv files in the same directory so it runs. \n",
    "\n",
    "One thing I think we really need to consider is how I am treating the Nans. They cant all be replaced by 1s or 0s. See more in writeup, but this is a serious struggle for this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from random import sample\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_meta_model(sk_algorithm, X, y, valid_datasets, maxes, kfold_num=10):\n",
    "\taccuracies = []\n",
    "\tkf = KFold(n_splits=kfold_num)\n",
    "\tkf.get_n_splits(X)\n",
    "\tfor train_index, test_index in tqdm(kf.split(X)):\n",
    "\t\tX_train, X_test = X[train_index], X[test_index]\n",
    "\t\ty_train, y_test = y[train_index], y[test_index] # dont use y_test\n",
    "\t\tds_train, ds_test = valid_datasets[train_index], valid_datasets[test_index] # valid_datasets is the list of datasets\n",
    "\t\tsk_algorithm.fit(X_train, y_train)\n",
    "\t\ty_pred = sk_algorithm.predict(X_test)\n",
    "\t\tcorrect = 0\n",
    "\t\tfor ds, prediction in zip(ds_test, y_pred):\n",
    "\t\t\tif prediction in maxes[ds]:\n",
    "\t\t\t\tcorrect += 1\n",
    "\t\taccuracies.append(correct/len(ds_test))\n",
    "\treturn max(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get maxes\n",
    "maxes = {}\n",
    "with open('optim_maxes.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        key = int(row[0])\n",
    "        values_str = ','.join(row[1:])\n",
    "        values_str = values_str.strip()\n",
    "        values = list(map(int, values_str.split(',')))\n",
    "        maxes[key] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset_path = 'IGTD.csv'\n",
    "df = pd.read_csv(meta_dataset_path) \n",
    "df.replace(np.nan, 0, inplace=True)\n",
    "df.replace(np.inf, 0, inplace=True)\n",
    "X = []\n",
    "y = []\n",
    "valid_datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    # check the first item in the ith row of df\n",
    "    if df.loc[i, 'dataset'] in maxes:\n",
    "        y.append(sample(maxes[df.loc[i, 'dataset']],k=1)[0])\n",
    "        X.append(df.iloc[i, 1:].tolist())\n",
    "        valid_datasets.append(df.loc[i, 'dataset'])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "valid_datasets = np.array(valid_datasets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Basic NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is exactly the same NN used as one of the 16 algorithms trained on the 466 datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=100000000)\n",
    "nn_accuracies = train_meta_model(nn, X, y, valid_datasets, maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "# get the accuraccies\n",
    "print('nn_accuracies: ', nn_accuracies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Grid Search "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't make it far with this. Definitely an area for future work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:43,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 100, 'solver': 'sgd'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:44,  4.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 100, 'solver': 'adam'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:44,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 200, 'solver': 'sgd'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:43,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 200, 'solver': 'adam'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:44,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 300, 'solver': 'sgd'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:44,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 300, 'solver': 'adam'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:43,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 100, 'solver': 'sgd'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:42,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 100, 'solver': 'adam'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:43,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 200, 'solver': 'sgd'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:42,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 200, 'solver': 'adam'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:44,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 300, 'solver': 'sgd'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:43,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 300, 'solver': 'adam'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:43,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 100, 'solver': 'sgd'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:45,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_accuracies:  0.6363636363636364 params:  {'activation': 'relu', 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'max_iter': 100, 'solver': 'adam'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:17,  4.18s/it]"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 50), (100, 50, 25)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Generate the parameter combinations\n",
    "param_combinations = ParameterGrid(param_grid)\n",
    "\n",
    "# Print the parameter combinations\n",
    "for params in param_combinations:\n",
    "    # Instantiate and train MLP model with the current parameters\n",
    "    mlp = MLPClassifier(**params)\n",
    "    # Your training code here\n",
    "    nn_accuracies = train_meta_model(nn, X, y, valid_datasets, maxes)\n",
    "    print('nn_accuracies: ', nn_accuracies, 'params: ', params, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this isnt exactly what I want because I want to try a bunch of parameters and then measure the accuracy with train_meta_model\n",
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h20.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o \n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.19\" 2023-04-18; OpenJDK Runtime Environment (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1); OpenJDK 64-Bit Server VM (build 11.0.19+7-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n",
      "  Starting server from /home/jupyter-as2273/.local/lib/python3.9/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpuph_4n1v\n",
      "  JVM stdout: /tmp/tmpuph_4n1v/h2o_jupyter_as2273_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpuph_4n1v/h2o_jupyter_as2273_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Denver</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 10 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_jupyter_as2273_4q0z0x</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>29.97 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.7 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       America/Denver\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    1 month and 10 days\n",
       "H2O_cluster_name:           H2O_from_python_jupyter_as2273_4q0z0x\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    29.97 Gb\n",
       "H2O_cluster_total_cores:    32\n",
       "H2O_cluster_allowed_cores:  32\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.7 final\n",
       "--------------------------  -------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# using the same X, y, valid_datasets from above\n",
    "# convert to h2o frames\n",
    "X_h2o = h2o.H2OFrame(X)\n",
    "y_h2o = h2o.H2OFrame(y)\n",
    "\n",
    "# convert to factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_models=20, max_runtime_secs=300, seed=1)\n",
    "aml.train(x=X_h2o.columns, y=y_h2o.columns[0], training_frame=X_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "H2OFrame is empty."
      ],
      "text/plain": [
       "H2OFrame is empty."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_train param, Dropping bad and constant columns: (and it dropped all of them)\n",
    "\n",
    "and then it said it cant complete in the 300 max runtime it was given. So it looks like this approach will *not* work "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
