{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_network import EmbeddingGenerator\n",
    "import os\n",
    "from scipy.io import arff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the arff file in\n",
    "filename = os.path.join('datasets', 'data_2.arff')\n",
    "\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    dataset = arff.loadarff(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"parses arff files into variables that are passed into pickle files that are then read into data_helper_covertype.py\"\"\"\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "# loop through the directory of datasets (all 466) and replace the file with the arr_file path \n",
    "# maybe I have a sperate file that runs this \n",
    "\n",
    "# specify the path to the ARFF file\n",
    "#arff_file = \"path/to/your/arff/file.arff\"\n",
    "filename = os.path.join('datasets', 'data_2.arff')\n",
    "\n",
    "\n",
    "# initialize variables\n",
    "NUM_SAMPLES = 0\n",
    "NUM_FEATURES = 0\n",
    "LABEL_COLUMN = \"\"\n",
    "BOOL_COLUMNS = []\n",
    "INT_COLUMNS = []\n",
    "STR_COLUMNS = []\n",
    "FLOAT_COLUMNS = []\n",
    "\n",
    "# read in the ARFF file\n",
    "with open(filename, \"r\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@attribute Sex {M,F,I}\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_360797/1216346661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# extract the attribute name and type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mattr_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"@attribute\\s+([\\w\\d_-]+)\\s+(\\w+)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# check the type of the attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"numeric\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# iterate over the lines in the ARFF file\n",
    "for line in lines:\n",
    "    if line.startswith(\"@data\"):\n",
    "        NUM_SAMPLES = len(lines) - lines.index(line) - 1\n",
    "    # check for attribute declarations\n",
    "    elif line.startswith(\"@attribute\"):\n",
    "        # extract the attribute name and type\n",
    "        print(line)\n",
    "        attr_name, attr_type = re.findall(r\"@attribute\\s+([\\w\\d_-]+)\\s+(\\w+)\", line)[0]\n",
    "        # basically this line is not matching some files in my arff file \n",
    "        # check the type of the attribute\n",
    "        if attr_type.lower() == \"numeric\":\n",
    "            INT_COLUMNS.append(attr_name)\n",
    "        elif attr_type.lower() == \"string\":\n",
    "            STR_COLUMNS.append(attr_name)\n",
    "        elif attr_type.lower() == \"real\":\n",
    "            FLOAT_COLUMNS.append(attr_name)\n",
    "        elif attr_type.lower() == \"{true,false}\":\n",
    "            BOOL_COLUMNS.append(attr_name)\n",
    "        # check for the label column\n",
    "        elif attr_type.lower() == \"nominal\":\n",
    "            LABEL_COLUMN = attr_name\n",
    "            values = re.findall(r\"{(.+)}\", line)[0]\n",
    "            values = [val.strip() for val in values.split(\",\")]\n",
    "            num_classes = len(values)\n",
    "            str_nuniquess = values\n",
    "            # count the number of features\n",
    "            NUM_FEATURES += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the extracted information\n",
    "print(f\"Number of samples: {NUM_SAMPLES}\")\n",
    "print(f\"Number of features: {NUM_FEATURES}\")\n",
    "print(f\"Label column: {LABEL_COLUMN}\")\n",
    "print(f\"Boolean columns: {BOOL_COLUMNS}\")\n",
    "print(f\"Integer columns: {INT_COLUMNS}\")\n",
    "print(f\"String columns: {STR_COLUMNS}\")\n",
    "print(f\"Floating-point columns: {FLOAT_COLUMNS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'variables.pkl' to be a name specific to the dataset \n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump((NUM_SAMPLES, NUM_FEATURES, LABEL_COLUMN, BOOL_COLUMNS, INT_COLUMNS, STR_COLUMNS, FLOAT_COLUMNS), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
